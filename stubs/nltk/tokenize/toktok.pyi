from _typeshed import Incomplete

from nltk.tokenize.api import TokenizerI as TokenizerI

class ToktokTokenizer(TokenizerI):
    NON_BREAKING: Incomplete
    FUNKY_PUNCT_1: Incomplete
    FUNKY_PUNCT_2: Incomplete
    EN_EM_DASHES: Incomplete
    AMPERCENT: Incomplete
    TAB: Incomplete
    PIPE: Incomplete
    COMMA_IN_NUM: Incomplete
    PROB_SINGLE_QUOTES: Incomplete
    STUPID_QUOTES_1: Incomplete
    STUPID_QUOTES_2: Incomplete
    FINAL_PERIOD_1: Incomplete
    FINAL_PERIOD_2: Incomplete
    MULTI_COMMAS: Incomplete
    MULTI_DASHES: Incomplete
    MULTI_DOTS: Incomplete
    OPEN_PUNCT: Incomplete
    CLOSE_PUNCT: Incomplete
    CURRENCY_SYM: Incomplete
    OPEN_PUNCT_RE: Incomplete
    CLOSE_PUNCT_RE: Incomplete
    CURRENCY_SYM_RE: Incomplete
    URL_FOE_1: Incomplete
    URL_FOE_2: Incomplete
    URL_FOE_3: Incomplete
    URL_FOE_4: Incomplete
    LSTRIP: Incomplete
    RSTRIP: Incomplete
    ONE_SPACE: Incomplete
    TOKTOK_REGEXES: Incomplete
    def tokenize(
        self, text: Incomplete, return_str: bool = False
    ) -> Incomplete: ...
